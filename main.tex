\documentclass[a4paper,UKenglish]{lipics-v2016}

% testing

\usepackage{mathrsfs}
\usepackage{datetime}
\usepackage{nameref}
\usepackage{bm}
\usepackage{proof}
\usepackage[section]{placeins}
\usepackage{float}
\usepackage{hyperref}
\usepackage{wrapfig}
\usepackage{varwidth}
\usepackage{color}
\usepackage{natbib}

\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
}

\newcommand{\clos}[2] {
  \langle #1; #2 \rangle
}

\newcommand{\app}[2] {
  (#1\, #2)
}

\newcommand{\machineframe}[4] {
  #1 \lbrack #2 \rbrack_#3 \Rightarrow #4
}

\newcommand{\aframe}[2] {
  \lbrack #1, #2 \rbrack_\alpha
}

% \newcommand{\nuframe}[3] {
%   #1 \lbrack #2 \rbrack_\nu\Rightarrow #3
% }

\newcommand{\nuframe}[3] {
  #1 \vdash #2 \Rightarrow_\nu #3
}

% \newcommand{\dframe}[5] {
%   (#1, #2) \lbrack #3 \rbrack_\delta\Rightarrow (#4, #5)
% }

\newcommand{\dframe}[5] {
  #1; #2 \vdash #3 \Rightarrow_\delta #4; #5
}

\newcommand{\pframe}[5] {
  #1; #2 \vdash #3 \Rightarrow_\textrm{pull} #4; #5
}

\newcommand{\pframebreak}[5] {
  #1; #2 \vdash #3 \\ \Rightarrow_\textrm{pull} #4; #5
}


% \newcommand{\pframe}[5] {
%   (#1, #2) \lbrack #3 \rbrack_\textrm{pull}\Rightarrow (#4, #5)
% }

\newcommand{\rframe}[7] {
  #1; #2; #3 \vdash #4 \Rightarrow_\rho #5; #6; #7
}

\newcommand{\sframe}[7] {
  #1; #2; #3 \vdash #4 \Rightarrow_s #5; #6; #7
}

\newcommand{\pr}[2] {
 (#1\, #2)
}

\newcommand{\eq}[2] {
 #1 = #2
}

\newcommand{\bd}[2] {
 #1/ #2
}

\newcommand{\aeq}[4] {
  \clos{#1}{#2} \approx \clos{#3}{#4}
}

\newcommand*{\transname}[1]{\textsc{#1}}

\newcommand*{\transrule}[3]{
  \infer[\transname{[#1]}]{#2}{#3}
}

\newcommand*{\transrulesp}[2]{
  \infer[]{#1}{#2}
}


%\bibliographystyle{plainurl}
\bibliographystyle{plainnat}

\title{Efficiency of a good but not linear nominal unification algorithm}

\keywords{$\alpha$-conversion; Binding operations; Efficiency; Unification}

\author[1]{Weixi Ma}
\author[2]{Jeremy G. Siek}
\author[3]{David Thrane Christiansen}
\author[4]{Daniel P. Friedman}
\affil[1]{Indiana University,
  \texttt{mvc@iu.edu}}
\affil[2]{Indiana University,
  \texttt{jsiek@indiana.edu}}
\affil[3]{Galois, Inc.,
  \texttt{dtc@galois.com}}
\affil[4]{Indiana University,
  \texttt{dfried@indiana.edu}}


\Copyright{Weixi Ma, Jeremy Siek, David Thrane Christiansen and Daniel P. Friedman}

\begin{document}

\maketitle

\begin{abstract}
  We present a nominal unification algorithm that runs in $O(n \times
  log(n) \times G(n))$ time, where $G$ is the functional inverse of
  Ackermann's function.  Nominal unification generates a set of
  variable assignments, if there exists one, that makes terms
  involving binding operations $\alpha$-equivalent. We preserve names
  while using special representations of de Bruijn numbers
  to enable efficient name management.
  % {\color{red}[The following sentence is not clear enough. --Jeremy]}
  We use Martelli-Montanari style multi-equation reduction
  to generate these name management problems from arbitrary unification terms.
  % {\color{red} The following phrase needs to be reworded.  ``the''
  %   indicates exactly one. But they had many ideas.  Which one are you
  %   referring to? Be specific.}  with the idea of Martelli-Montanari.
\end{abstract}

\section{Introduction and background}

Equational theories over terms, such as $\alpha$, $\beta$, and $\eta$
in the $\lambda$-calculus~\citep{church_calculi_1941}, are
a critical component of
programming languages and formal systems.  As users of logic
programming languages and theorem provers, we desire such rules to be
available out of the box. Two theories provide
this convenience: higher-order pattern unification of
\citet{miller_logic_1989} and nominal unification of
\citet{urban_nominal_2004}. Higher-order pattern unification, which
handles a fragment of the $\beta\eta$-rules, is the foundation of
Isabelle~\citep{paulson_natural_1986},
$\lambda$Prolog~\citep{nadathur_overview_1988}, and
Twelf~\citep{pfenning_system_1999}.  Nominal unification, which
focuses on the $\alpha$-rule, has inspired extensions of logic
programming languages such as $\alpha$Prolog~\citep{cheney_prolog:_2004}
and $\alpha$Kanren~\citep{byrd_kanren_2007}, as well as theorem
provers such as nominal Isabelle~\citep{urban_nominal_2005} and
$\alpha$LeanTAP~\citep{near_leantap:_2008}.  Although these two
theories can be reduced to one another~\citep{cheney_relating_2005,
  levy_nominal_2012}, implementing higher-order pattern unification is
more complicated because it has to deal with $beta$-reduction and
capture-avoiding substitution. On the other hand, an implementation of
nominal unification,
in which unification does not involve explicit $beta$-reduction,
is more straightforward and easier to formalize.

% Beyond unification,
% techniques from the nominal approach, such as swapping and freshness
% environments, have impacted the areas as diverse as
% rewriting~\citep{fernandez_nominal_2004, fernandez_nominal_2005,
%   fernandez_nominal_2007, aoto_nominal_2016}, equational
% theories~\citep{ayala-rincon_nominal_2016}, and reasoning about
% bindings in abstract syntax~\citep{pitts_metalanguage_2000,
%   gabbay_new_2002}.
Concerning time complexity, \citet{qian_unification_1996} has proven that
higher-order pattern unification is decidable in linear time.  On the
other hand, it has been an open problem whether there exists a nominal
unification algorithm that can do better than
$O(n^2)$. \citet{levy_nominal_2012} give a quadratic time reduction
from nominal unification to higher-order pattern unification.
Meanwhile, algorithmic advances by \citet{paterson_linear_1978} and
\citet{martelli_efficient_1982} for unification have inspired many
improvements to the efficiency of nominal unification. Ideas
like applying swappings lazily and composing swappings eagerly and
sharing subterms have also been explored. \citet{calves_complexity_2010}
describes quadratic algorithms that extend the Paterson-Wegman and
Martelli-Montanari's algorithms with name (atom) handling;
\citet{levy_efficient_2010} describe a quadratic algorithm that
reduces unification problems to a sequence of freshness and equality
constraints and then solves the constraints.

The inefficiency of these nominal unification algorithms comes from
the swapping actions. To decide the $\alpha$-equivalence of
two names, we need to linearly traverse a list whose length 
is the number of binders.  One might try to replace these
lists with a more efficient lookup structure, such as a hash table,
but then composing two swappings would take linear time, and that
operation is also rather frequent.  Here we present an algorithm that
does not use swappings but instead represents names with de Bruijn
numbers. De Bruijn numbers enable the use of persistent hash tables, in
particular, \citeauthor{bagwell_ideal_2001}'s Hash Array Mapped Trie
(HAMT). HAMTs provide efficient lookup and
they use sharing to avoid the linear-time costs that would normally be
associated with duplicating a hash table.

We organize this paper as follows.  In section~\ref{closures}, we provide
an alternative representation of de Bruijn numbers that is suitable
for unification.  In section~\ref{unify}, we describe the abstract
machines for name management and unification.  In
section~\ref{efficiency}, we discuss the time complexity of this
algorithm. The proofs of our claims are in progress and are available
at \href{https://github.com/mvcccccc/UNIF2018}{the authors' Github}
\footnote{https://github.com/mvcccccc/UNIF2018},
formalized in Agda.
  
\section{De Bruijn numbers should coexist with names}
\label{closures}

\begin{wrapfigure}{r}{0.5\textwidth}
  \begin{minipage}[b]{0.4\textwidth}
   \caption{Terms\label{table:terms}}
  \begin{tabular}{r l l l}
    $t,l,r$ & $::=$ & $a$ & name \\
    & $|$ & $\lambda a.t$ & abstractions \\
    & $|$ & $\app{l}{r}$ & combinations \\
    \end{tabular}
    \end{minipage}

\begin{minipage}[b]{0.4\textwidth}

  \caption{Free and bound\label{table:fb}}
  \begin{tabular}{l}
    \transrule{Free}
    {\Phi \vdash \texttt{Fr}\,\,a}
    {a \notin \Phi} \\ \\

    \transrule{Bound}
    {\Phi \vdash \texttt{Bd}\,\,a\,\,i}
    {
    (\texttt{name$\rightarrow$idx}\, \Phi\,a) = i \\
    (\texttt{idx$\rightarrow$name}\, \Phi\,i) = a
    }
   \end{tabular}
\end{minipage}

\begin{minipage}[b]{0.4\textwidth}

  \caption{$\approx$-rules\label{table:same-name}}
  \begin{tabular}{l}
    \transrule{Same-Free}
    {\aeq{a_1}{\Phi_1}{a_2}{\Phi_2}}{%
    a_1 = a_2 \hfill \\
    \Phi_1 \vdash \texttt{Fr}\,\, a_1 \quad
    \Phi_2 \vdash \texttt{Fr}\,\, a_2 
    } \\ \\

    \transrule{Same-Bound}
    {\aeq{a_1}{\Phi_1}{a_2}{\Phi_2}}
    {%
    i_1 = i_2 \hfill \\
      \Phi_1 \vdash \texttt{Bd}\,\, a_1\,\, i_1 \quad
    \Phi_2 \vdash \texttt{Bd}\,\, a_2\,\, i_2 
    }
 \end{tabular}
\end{minipage}


\end{wrapfigure}

De Bruijn numbers are a technique for representing syntax with binding
structure~\citep{de_bruijn_lambda_1972}.  A \emph{de Bruijn number} is
a natural number that indicates the distance from a name occurrence to
its corresponding binder.  When all names in an expression are
replaced with their corresponding de Bruijn numbers, a direct
structural equality check is sufficient to decide
$\alpha$-equivalence.  A few programming
languages~\citep{norell_towards_2007} use de Bruijn numbers in their
internal representations for machine manipulation during operations
such as type checking.  The idea of using names for free variables and
numbers for bound variables, known as the locally nameless
approach~\citep{chargueraud_locally_2012}, is employed for formalizing
meta-theories~\citep{aydemir_nominal_2006,
  aydemir_engineering_2008}.  Also, de Bruijn numbers, combined with
explicit substitution, have been introduced in higher-order
unification~\citep{dowek_higher_2000} to improve the efficiency of
unification.

Despite the convenience when implementing $\alpha$-equivalence,
programs written with de Bruijn numbers are notoriously difficult for
humans to read and understand.  What's worse, as pointed out by
~\citet{berghofer_head--head_2007}, translating
pencil-and-paper style proofs to versions using de Bruijn numbers is
surprisingly involved: such a translation may alter the structure of
proofs. Thus, reproducing proofs with explicit names from de
Bruijn numbers is difficult or even impossible.  Thus, for the sake of
both readers and writers of proofs, it is worth providing an interface
with names.

If our concern is simply deciding $\alpha$-equivalence between
expressions, an easy way to use de Bruijn numbers while preserving
names is to traverse the expressions, annotate each name with its de
Bruijn number, then read-back the expressions without numbers.  This
approach, however, does not work for unification, because it only
contains the mapping \emph{from names to numbers}.  In unification
modulo $\alpha$-equivalence, one frequently needs the mapping
\emph{from numbers to names} to decide what name to assign to a
unification variable.

We represent de Bruijn numbers by \emph{static closures},
referred to as \emph{closures}.  Closures preserve the
mappings in both directions: names to numbers and numbers to names.

\begin{definition}
  A \emph{closure} is an ordered pair $\clos{t}{\Phi}$ of a term $t$,
  defined in Figure~\ref{table:terms}, and a scope $\Phi$, where the
  scope is an ordered list of names for the binders in the enclosing
  context. The name of the innermost binder is written first in $\Phi$.
\end{definition}

When the term of a closure is a name, the closure itself represents a
de Bruijn number.  For example, consider the term
$\lambda\,x.\lambda\,y.x$. The de Bruijn number of the name $x$ is $1$
and the closure-representation of this number is $\clos{x}{(y\,x)}$.
We can retrieve the number-representation by finding the position of
the first appearance of the name in the scope. In this case, the
position of $x$ in the scope $(y\,x)$ is $1$, which is its de Bruijn
number. Similarly, the de Bruijn number of $y$ is $0$.

A scope, as a list, supports three operations: \texttt{ext},
which extends the scope by adding a name to the front of the scope;
\texttt{idx$\rightarrow$name}, which returns the name of a given index
starting from the leftmost name in the scope; and
\texttt{name$\rightarrow$idx}, which returns the location of the first
appearance of a given name counting from the front of the scope.  As we
are building the scope in reversed order, if repeated names appear, the
first appearance in a scope shadows the others.

\begin{wrapfigure}{r}{0.5\textwidth}
  \caption{Unification terms and problems\label{table:new-terms}}
    \begin{tabular}{r l l l}  
    $X$   &       &     & vars \\
      $xs,ys$ & $::=$ & $\epsilon$& list of vars \\
      & $|$&  $X,xs$ &  \\
    $t,l,r$ & $::=$ & $a$ & names \\
    & $|$ & $\lambda a.t$ & abstractions \\
    & $|$ & $\app{l}{r}$ & combinations \\
      & $|$ & $X$ & \\
      $e_\nu$  & $::=$ & $(a,\Phi) = (a,\Phi)$ & $\nu$-equation \\
           & $|$ &  $(X,\Phi) = (a,\Phi)$ \\
      $p_\nu$  & $::=$ & $\epsilon$ & $\nu$-problems \\
           & $|$ & $e_\nu, p_\nu$ \\
      $e_\delta$  & $::=$& $(X,\Phi) = (X,\Phi)$ & $\delta$-equation \\
      $p_\delta$  & $::=$ & $\epsilon$ & $\delta$-problems \\
           & $|$ & $e_\delta, p_\delta$
    \end{tabular}
\end{wrapfigure}

Now in Figure~\ref{table:fb}, we can talk about free and bound
variables ``constructively,'' with de Bruijn numbers serving as
evidence that variables are well-scoped.  When a name, $a$, does not
appear in the scope, $\Phi$, we say, ``$a$ is free with respect to
$\Phi$,'' written as $\Phi \vdash \texttt{Fr}\, a$; when $a$'s first
appearance in $\Phi$ is the position $i$, we say, ``$a$ is bound at
$i$ with respect to $\Phi$,'' written as $\Phi \vdash \texttt{Bd}\,
a\,i$.  The \transname{bound} rule has two premises to be algorithmic
in both directions, that is, given a name we can find its index and
given an index we can find its name, if no shadowings occur.
Figure~\ref{table:same-name} defines the rules to decide whether two
names are $\alpha$-equivalent w.r.t their scopes, written as
$\aeq{a_1}{\Phi_1}{a_2}{\Phi_2}$.

% temporary
\pagebreak

\section{Unification}
\label{unify}

\begin{wrapfigure}{r}{0.5\textwidth}
  \begin{minipage}[b]{0.4\textwidth}
  \caption{$\nu$-machine}\label{machine:nu}
    \framebox{$\nuframe{\sigma}{p_\nu}{\sigma}$} \\ \\
  \end{minipage}

\begin{minipage}[b]{0.4\textwidth}
  \begin{tabular}{l}
    \transrule{Empty}
    {\nuframe{\sigma_0}{\epsilon}{\sigma_0}}{} \\ \\

    \transrule{N-N}
    {\nuframe{\sigma_0}{\eq{\clos{a_1}{\Phi_1}}{\clos{a_2}{\Phi_2}},\,p}{\sigma_1}}
    {
        \nuframe{\sigma_0}{p}{\sigma_1} \\
    \clos{a_1}{\Phi_1} \approx \clos{a_2}{\Phi_2} \hfill
    } \\ \\


    \transrule{N-V}
    {\nuframe{\sigma_0}{\eq{\clos{a_1}{\Phi_1}}{\clos{a_2}{\Phi_2}},\,p}{\sigma_1}}
    {
    \clos{a_1}{\Phi_1} \approx \clos{a_2}{\Phi_2} \hfill \\
        \nuframe{\{X_2/a_2\}\cup\sigma_0}{p}{\sigma_1} 
    }

  \end{tabular}
  \end{minipage} \\
%\end{wrapfigure}

%\begin{wrapfigure}{r}{0.5\textwidth}
%\begin{figure}[htbp]
  \begin{minipage}[b]{\textwidth}
  \caption{$\delta$-machine and the pull operation}\label{machine:delta}
    \fbox{\begin{varwidth}{\textwidth}
        $\dframe{\sigma}{p_\delta}{xs}{\sigma}{p_\delta}$ \\
        $\pframe{\sigma}{xs}{p_\delta}{\sigma}{xs}$
        \end{varwidth}} \\ \\
  \end{minipage}

\begin{minipage}[b]{0.4\textwidth}
  \begin{tabular}{l}

    \transrule{Empty-Xs}
    {\dframe{\sigma}{\delta}{\epsilon}{\sigma}{\delta}}
    {} \\ \\
    
    \transrule{Empty-D}
    {\dframe{\sigma}{\epsilon}{xs}{\sigma}{\epsilon}}
    {} \\ \\ 

    \transrule{Pull}
    {\dframe{\sigma_0}{\delta_0}{X, xs_0}{\sigma_1}{\delta_1}}
    {
          \pframe{\sigma_0}{xs_0}{\delta_0(X)}{\sigma_0'}{xs_1} \\
          \dframe{\sigma_0'}{\delta_0 \setminus \delta_0(X)}{xs_1}{\sigma_1}{\delta_1}
    } \\ \\

    \transrule{Empty}
    {\pframe{\sigma}{xs}{\emptyset}{\sigma}{xs}}
    {} \\ \\

    \transrulesp
    {\pframe{\sigma_0}{xs_0}{\eq{\clos{X_1}{\Phi_1}}{\clos{X_2}{\Phi_2}}, p}{\sigma_1}{xs_1}}
    {%
    \aeq{a_1}{\Phi_1}{a_2}{\Phi_2} \hspace{20mm} \transname{[N-N]} \\
    \sigma_0(X_1) = a_1 \quad \sigma_0(X_2) = a_2  \hfill \\
    \pframe{\sigma_0}{xs_0}{p}{\sigma_1}{xs_1} \hfill 
    } \\ \\

    \transrulesp
    {\pframe{\sigma_0}{xs_0}{\eq{\clos{X_1}{\Phi_1}}{\clos{X_2}{\Phi_2}}, p}{\sigma_1}{xs_1}}{%
    \aeq{a_1}{\Phi_1}{a_2}{\Phi_2} \hfill \hspace{10mm} \transname{[N-V]} \\
    \sigma_0(X_1) = a_1 \quad X_2\notin dom(\sigma_0) \hfill \\
              \pframe{\{Y_2/a_2\}\cup\sigma_0}{(Y_2, xs_0)}{p}{\sigma_1}{xs_1}  \hfill
    } \\ \\

\end{tabular}

\end{minipage}
%\end{figure}
\end{wrapfigure}

In Figure~\ref{table:new-terms}, we introduce unification variables,
which we abbreviate as \emph{var}.  First, let's consider a simplified unification
problem: a variable can only be instantiated by a name, that is,
finding the unifier of two terms that share the same structure but
differ in names and variables.  A unifier consists of two parts:
$\sigma$ and $\delta$.

A \emph{substitution}, $\sigma$, is a partial finite function from
a unification variable,
  $X_i$, to a terms, $t_i$.  For readability, we write $\sigma$ as a
  set, $\{\bd{X_1}{t_1}, ..., \bd{X_j}{t_j}\}$ and we write
  $\{\bd{X}{t}\} \cup \sigma$ for extending $\sigma$ with $\bd{X}{t}$.
  For the simplified problems, we restrict $t$ to a name.

  A \emph{closure equation} is a pair of two closures that are
  $\alpha$-equivalent. $\Delta$ stands for a set of closure equations.
  We write $\Delta$ as $\{\pr{\clos{t_1}{\Phi_1}}{\clos{t_1'}{\Phi_1'}},
  ..., \pr{\clos{t_i}{\Phi_1}}{\clos{t_i'}{\Phi_1'}}\}$ and we write
  $\{\pr{\clos{t}{\Phi}}{\clos{t'}{\Phi'}}\}\cup\Delta$ for extending
  $\Delta$ with $\pr{\clos{t}{\Phi}}{\clos{t'}{\Phi'}}$. 
  $\delta$ is a special form of $\Delta$: for each equation in
  $\delta$, the terms on both sides are variables.
  Given a variable $X$, $\delta(X)$ yields the list of
  closure equations where $X$ appears at least once.

  The simplified problem is about solving three kinds of problems:
  unifying a closure equation that has a name term on one side
  and a var term on the other side,
  abbreviated to \transname{N-V},
  and similarly \transname{N-N} and \transname{V-V}.
% {\color{red}[ talk about the equations and problems
%     defined in Figure~\ref{table:new-terms} ]}
As defined in Figure~\ref{table:new-terms},
we refer to a \transname{N-N} or \transname{N-V} equation as
an \emph{$e_\nu$} and refer to a
\transname{V-V} equation as an \emph{$e_\delta$}.
Given two lists of these closure equations,
$p_\nu$ and $p_\delta$,
we first run the
$\nu$-machine, defined in Figure~\ref{machine:nu},
on $p_\nu$ to generate a substitution.
The $\delta$-machine, defined in Figure~\ref{machine:delta},
then computes the final unifier on three inputs:
the substitution resulting from the $\nu$-machine,
$\delta$, and a list of known variables, initialized by
the domain of the substitution.
If no transitions apply, the machine
fails and the unification problem has no unifier.


\begin{lemma}\label{lemma:numachine}
 For all finite input, the $\nu$-machine and the $\delta$-machine
 terminate; for all input, the $\nu$-machine and the $\delta$-machine
 succeed with the mgu if and only if there exists one.
\end{lemma}
\begin{proof}
    By structural induction on the transitions of the machines.
\end{proof}


Now the question is how to generalize the previous algorithm, that is,
given two arbitrary terms, where a variable may be instantiated by any
term besides names, can we re-shape the two terms to create a proper
input to the two machines?

%\begin{wrapfigure}{r}{0.5\textwidth}
    \begin{figure}[htbp]
  \caption{Multi-equations}\label{table:multi}
   \begin{minipage}[b]{\textwidth}
      \begin{tabular}{r l l l}  
      $U$ & $::=$ & $\epsilon$& list of multi-equations \\
      & $|$&  $e,U$ &  \\ \\
      $e$ & $::=$ & $\pr{\clos{t}{\Phi}}{\clos{t}{\Phi}}$& multi-equation \\
      & $|$&  $\clos{t}{\Phi},e$ &  \\ \\
    \end{tabular}

      \caption{$\rho$-machine}\label{table:rmachine}
     \end{minipage}
   \begin{minipage}[b]{\textwidth}
    \fbox{\begin{varwidth}{\textwidth}
        $\rframe{p_\nu}{p_\delta}{\sigma}{U}{p_\nu}{p_\delta}{\sigma}$ \\
        $\sframe{p_\nu}{p_\delta}{\sigma}{e}{p_\nu}{p_\delta}{\sigma}$ 
        \end{varwidth}}
  \end{minipage} \\ \\

  \begin{minipage}[b]{\textwidth}
  \begin{tabular}{l}

    \transrule{Empty}
    {\rframe{p_0}{\delta_0}{\sigma_0}{\epsilon}{p_0}{\delta_0}{\sigma_0}}
    {} \\ \\

    \transrule{Step}
    {\rframe{p_0}{\delta_0}{\sigma_0}{(e, U)}{p_1}{\delta_1}{\sigma_1}}
    {%
    \sframe{p_0}{\delta_0}{\sigma_0}{e}{p_0'}{\delta_0'}{\sigma_0'} \\
    \rframe{p_0'}{\delta_0'}{\sigma_0'}{U}{p_1}{\delta_1}{\sigma_1} 
    } \\ \\

    \transrule{N-N}
    {\sframe{p_0}{\delta_0}{\sigma_0}{\pr{\clos{a_1}{\Phi_1}}{\clos{a_2}{\Phi_2}}}{p_1}{\delta_0}{\sigma_0}}
    {%
    p_1 = \pr{\clos{a_1}{\Phi_1}}{\clos{a_2}{\Phi_2}} \cup p_0
    } \\ \\

    \transrule{N-V}
    {\sframe{p_0}{\delta_0}{\sigma_0}{\pr{\clos{a_1}{\Phi_1}}{\clos{X_2}{\Phi_2}}}{p_1}{\delta_0}{\sigma_0}}
    {%
    p_1 = \pr{\clos{a_1}{\Phi_1}}{\clos{X_2}{\Phi_2}} \cup p_0
    } \\ \\ 

    \transrule{V-V}
    {\sframe{p_0}{\delta_0}{\sigma_0}{\pr{\clos{a_1}{\Phi_1}}{\clos{X_2}{\Phi_2}}}{p_0}{\delta_1}{\sigma_0}}
    {%
    \delta_1 = \pr{\clos{X_1}{\Phi_1}}{\clos{X_2}{\Phi_2}} \cup \delta_0
    } \\ \\

    \transrule{C-C}
    {\sframe{p_0}{\delta_0}{\sigma_0}{\pr{\clos{\app{l_1}{r_1}}{\Phi_1}}{\clos{\app{l_2}{r_2}}{\Phi_2}}}{p_1}{\delta_1}{\sigma_1}}
    {%
              \sframe{p_0}{\delta_0}{\sigma_0}{\pr{\clos{l_1}{\Phi_1}}{\clos{l_2}{\Phi_2}}}{p_0'}{\delta_0'}{\sigma_0'} \\
    \sframe{p_0'}{\delta_0'}{\sigma_0'}{\pr{\clos{r_1}{\Phi_1}}{\clos{r_2}{\Phi_2}}}{p_1}{\delta_1}{\sigma_1}
    } \\ \\

    \transrule{A-A}
    {\sframe{p_0}{\delta_0}{\sigma_0}{\pr{\clos{\lambda\,a_1.t_1}{\Phi_1}}{\clos{\lambda\,a_2.t_2}{\Phi_2}}}{p_1}{\delta_1}{\sigma_1}}
    {%
     \Phi_1' = (\texttt{ext}\, \Phi_1\, a_1) \quad \Phi_2' = (\texttt{ext}\, \Phi_2\, a_2) \hfill \\
    \sframe{p_0}{\delta_0}{\sigma_0}{\pr{\clos{t_1}{\Phi_1'}}{\clos{t_2}{\Phi_2'}}}{p_1}{\delta_1}{\sigma_1}
    } \\ \\ 

    \transrule{V-C}
    {\sframe{p_0}{\delta_0}{\sigma_0}{\pr{\clos{X_1}{\Phi_1}}{\clos{\app{l_2}{r_2}}{\Phi_2}}}{p_1}{\delta_1}{\sigma_1}}{%
    \sframe{p_0}{\delta_0}{\{X_1/(X_l, X_r)\}\cup\sigma_0'}{\pr{\clos{X_l}{\Phi_1}}{\clos{l_2}{\Phi_2}}}{p_0'}{\delta_0'}{\sigma_0'} \\
    \sframe{p_0'}{\delta_0'}{\sigma_0'}{\pr{\clos{X_r}{\Phi_1}}{\clos{r_2}{\Phi_2}}}{p_1}{\delta_1}{\sigma_1}  \hfill
    } \\ \\

    \transrule{V-A}
    {\sframe{p_0}{\delta_0}{\sigma_0}{\pr{\clos{X_1}{\Phi_1}}{\clos{\lambda\,a_2.t_2}{\Phi_2}}}{p_1}{\delta_1}{\sigma_1}}
    {%
    \Phi_1' = (\texttt{ext}\, \Phi_1\, a_1) \quad \Phi_2' = (\texttt{ext}\, \Phi_2\, a_2)  \hfill \\
    \sframe{p_0}{\delta_0}{\bd{X_1}{\lambda\,a_1.X_t}\cup\sigma_0'}{\pr{\clos{X_t}{\Phi_1'}}{\clos{t_2}{\Phi_2'}}}{p_1}{\delta_1}{\sigma_1}
    }
     
  \end{tabular}
  \end{minipage}
\end{figure}
%\end{wrapfigure}


Here we use the idea of \citet{martelli_efficient_1982}:
finding the shared shape of two terms by computing
the common parts and frontiers over a multi-equation.
They define the \emph{common part} of two terms to be
a term obtained by superimposing,
and the \emph{frontier} to be the substitution that
captures the differences between each term and the common part.
For example, given distinct names $a$, $b$, and $c$,
distinct vars $X$ and $Y$,
and two terms $(a\,X)$ and $(Y\,(b\,c))$,
the common part is the term $(Y\,X)$,
and the frontier is the substitution $\{\bd{Y}{a},\,\bd{X}{(b\,c)}\}$.
A multi-equation, defined in Figure~\ref{table:multi}, groups together many closures to be unified,
where the variable closures are on the left-hand side,
and the non-variable closures are on the right-hand side.

The $\rho$-machine, defined in
Figure~\ref{table:rmachine}, 
reduces an arbitrary nominal unification problem to
$p_\nu$, $p_\delta$, and a substitution where the codomain is unrestricted.
Each $\Rightarrow_s$ transition computes the common part and the frontier
of a multi-equation. For readability, the sketch only shows the rules
for multi-equations with one left-hand side and one right-hand side.
A multi-equation with more than one closures on one side is handled by
simultaneously applying the rule to all closures.
Unlike the Martelli-Montanari algorithm,
the $\rho$-machine finds the maximum common part instead of the minimum.
Thus, in the \transname{V-C} and \transname{V-A} rules, we need to create
new names and new variables
to extend the shape of variables with combinations and abstractions.
The ordering of multi-equation is the same with Martelli-Montanari:
for each multi-equation, we count the appearances of its left-hand side vars
in other multi-equations of U and select the multi-equation associated
with the smallest counter each time.

\section{A note on time complexity}
    \label{efficiency}

In the previous sections, we represent scopes by lists for simplicity,
but lists are inefficient for variable lookup.  To have better time
complexity, we represent a scope with a counter and two persistent
hashtables, also known as HAMT~\citep{bagwell_ideal_2001}.  One
hashtable maps from names to numbers, the other maps from numbers to
names, and the counter is used to track the de Bruijn number.  When we
extend a scope with a name, we extend the two hashtables with the
corresponding maps and add one to the counter.  A persistent
hashtable, in practice, has constant time for update and lookup,
although the worst case scenario could be $O(log(n))$.  Thus,
\texttt{ext}, \texttt{idx$\rightarrow$name}, and
\texttt{name$\rightarrow$idx} are all logarithmic time.  In addition,
using persistent structures avoids copying the entire data-structure
when branching, in particular, during the \transname{app-app} rule of
the $\rho$-machine.
Also, we implement $\delta$ with a hashtable that maps from a variable to
the list that contains its closure equations,
i.e., the equation $\aeq{X}{\Phi_1}{Y}{\Phi_2}$
exists in both $X$'s entry and $Y$'s entry in the hashtable.

Given the above optimizations, the $\nu$-machine and the
$\delta$-machine are both worst case $O(n \times log(n))$,
where $n$ is the sum of name and variable occurrences.
The algorithm of Martelli-Montanari is $O(n \times G(n))$, when
representing sets with UNION-FIND~\citep{tarjan_efficiency_1975}, where
$n$ is the number of variable occurrences in the original terms.  The
$\rho$-machine is similar except that two new factors are involved:
the update operation of HAMT and the generation of names and
variables.  We consider the former one to have $O(log(n))$ complexity,
and we implement name and variable creation with state
monads~\citep{moggi_notions_1991} in
constant time.  Thus reducing an arbitrary unification problem to the
input of the $\nu$ and $\delta$ machines becomes $O(n \times log(n) \times
G(n))$.

\section*{Acknowledgment}
We thank Christian Urban for the discussion and inspiration
and the anonymous reviewers for their comments and suggestions.

\bibliography{main}

\end{document}
%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
